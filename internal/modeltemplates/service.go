package modeltemplates

import (
	"fleet-navigator/internal/llamaserver"
	"fmt"
	"log"
	"regexp"
	"sync"
)

// Service verwaltet Model-Templates und die Message-Adaption
type Service struct {
	repo      *Repository
	templates []ModelTemplate
	mu        sync.RWMutex
}

// NewService erstellt einen neuen Template-Service
func NewService(repo *Repository) *Service {
	s := &Service{
		repo: repo,
	}
	// Templates initial laden
	s.ReloadTemplates()
	return s
}

// ReloadTemplates l√§dt die Templates aus der Datenbank neu
func (s *Service) ReloadTemplates() error {
	templates, err := s.repo.GetActive()
	if err != nil {
		return err
	}

	s.mu.Lock()
	s.templates = templates
	s.mu.Unlock()

	log.Printf("Model-Templates geladen: %d aktive Templates", len(templates))
	return nil
}

// GetTemplateForModel findet das passende Template f√ºr einen Modellnamen
func (s *Service) GetTemplateForModel(modelName string) *ModelTemplate {
	s.mu.RLock()
	defer s.mu.RUnlock()

	for _, t := range s.templates {
		matched, err := regexp.MatchString(t.Pattern, modelName)
		if err != nil {
			log.Printf("Regex-Fehler f√ºr Pattern %s: %v", t.Pattern, err)
			continue
		}
		if matched {
			log.Printf("Template gefunden f√ºr %s: %s (Strategy: %s)",
				modelName, t.Name, t.SystemEmbedStrategy)
			return &t
		}
	}

	// Kein Template gefunden - Fallback auf Native
	log.Printf("Kein Template f√ºr %s gefunden, verwende Native-Strategie", modelName)
	return &ModelTemplate{
		Name:                "Fallback",
		SupportsSystemRole:  true,
		SystemEmbedStrategy: StrategyNative,
	}
}

// AdaptMessages passt die Messages f√ºr das angegebene Modell an
func (s *Service) AdaptMessages(modelName string, messages []llamaserver.ChatMessage) []llamaserver.ChatMessage {
	template := s.GetTemplateForModel(modelName)

	// Native Strategie = keine √Ñnderung n√∂tig
	if template.SystemEmbedStrategy == StrategyNative {
		return messages
	}

	// System-Prompt extrahieren
	var systemPrompt string
	var otherMessages []llamaserver.ChatMessage

	for _, msg := range messages {
		if msg.Role == "system" {
			systemPrompt = msg.Content
		} else {
			otherMessages = append(otherMessages, msg)
		}
	}

	// Kein System-Prompt = keine √Ñnderung n√∂tig
	if systemPrompt == "" {
		return messages
	}

	// Je nach Strategie anpassen
	switch template.SystemEmbedStrategy {
	case StrategyEmbedInUser:
		return s.embedSystemInUser(template, systemPrompt, otherMessages)
	case StrategyPrependUser:
		return s.prependSystemAsUser(template, systemPrompt, otherMessages)
	default:
		return messages
	}
}

// embedSystemInUser bettet den System-Prompt in die erste User-Nachricht ein
func (s *Service) embedSystemInUser(template *ModelTemplate, systemPrompt string, messages []llamaserver.ChatMessage) []llamaserver.ChatMessage {
	result := make([]llamaserver.ChatMessage, 0, len(messages))
	systemEmbedded := false

	for _, msg := range messages {
		if msg.Role == "user" && !systemEmbedded {
			// System-Prompt mit Prefix/Suffix einbetten
			prefix := template.SystemPrefix
			suffix := template.SystemSuffix

			if prefix == "" {
				prefix = "[SYSTEM-ANWEISUNGEN]\n"
			}
			if suffix == "" {
				suffix = "\n[ENDE]\n\nNachricht: "
			}

			enhancedContent := fmt.Sprintf("%s%s%s%s", prefix, systemPrompt, suffix, msg.Content)
			result = append(result, llamaserver.ChatMessage{
				Role:    "user",
				Content: enhancedContent,
			})
			systemEmbedded = true
		} else {
			result = append(result, msg)
		}
	}

	// Falls keine User-Nachricht gefunden wurde
	if !systemEmbedded && systemPrompt != "" {
		result = append([]llamaserver.ChatMessage{{
			Role:    "user",
			Content: template.SystemPrefix + systemPrompt + template.SystemSuffix,
		}}, result...)
	}

	log.Printf("üîÑ System-Prompt eingebettet f√ºr %s (%d Zeichen)", template.Name, len(systemPrompt))
	return result
}

// prependSystemAsUser f√ºgt den System-Prompt als erste User-Nachricht hinzu
func (s *Service) prependSystemAsUser(template *ModelTemplate, systemPrompt string, messages []llamaserver.ChatMessage) []llamaserver.ChatMessage {
	prefix := template.SystemPrefix
	suffix := template.SystemSuffix

	if prefix == "" {
		prefix = "Kontext: "
	}
	if suffix == "" {
		suffix = ""
	}

	systemMsg := llamaserver.ChatMessage{
		Role:    "user",
		Content: prefix + systemPrompt + suffix,
	}

	// F√ºge eine leere Assistant-Antwort hinzu, um den Kontext zu etablieren
	ackMsg := llamaserver.ChatMessage{
		Role:    "assistant",
		Content: "Verstanden, ich werde diese Anweisungen befolgen.",
	}

	result := append([]llamaserver.ChatMessage{systemMsg, ackMsg}, messages...)

	log.Printf("üîÑ System-Prompt als User-Nachricht vorangestellt f√ºr %s", template.Name)
	return result
}

// GetAll gibt alle Templates zur√ºck
func (s *Service) GetAll() ([]ModelTemplate, error) {
	return s.repo.GetAll()
}

// GetByID gibt ein Template zur√ºck
func (s *Service) GetByID(id int64) (*ModelTemplate, error) {
	return s.repo.GetByID(id)
}

// Create erstellt ein neues Template
func (s *Service) Create(t *ModelTemplate) error {
	if err := s.repo.Create(t); err != nil {
		return err
	}
	return s.ReloadTemplates()
}

// Update aktualisiert ein Template
func (s *Service) Update(t *ModelTemplate) error {
	if err := s.repo.Update(t); err != nil {
		return err
	}
	return s.ReloadTemplates()
}

// Delete l√∂scht ein Template
func (s *Service) Delete(id int64) error {
	if err := s.repo.Delete(id); err != nil {
		return err
	}
	return s.ReloadTemplates()
}

// SeedDefaults f√ºgt die Standard-Templates ein
func (s *Service) SeedDefaults() error {
	if err := s.repo.SeedDefaults(); err != nil {
		return err
	}
	return s.ReloadTemplates()
}
